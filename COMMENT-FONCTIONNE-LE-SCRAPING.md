# ğŸ” Comment fonctionne le Scraping ?

Guide complet pour comprendre le fonctionnement du scraping dans l'app Supernatural.

## ğŸ“š Concept gÃ©nÃ©ral

Le **web scraping** est une technique qui permet d'extraire automatiquement des donnÃ©es depuis des pages web. C'est comme si un robot visitait un site web, lisait son contenu HTML et en extrayait les informations pertinentes.

### Analogie simple

Imaginez que vous visitez manuellement le site HonCon pour voir s'il y a de nouvelles conventions :
1. Vous ouvrez votre navigateur
2. Vous allez sur www.honcon.de
3. Vous lisez la page
4. Vous notez : nom, date, lieu, invitÃ©s
5. Vous rÃ©pÃ©tez pour chaque site

Le scraper fait **exactement la mÃªme chose**, mais automatiquement et en quelques secondes !

---

## ğŸ› ï¸ Technologies utilisÃ©es

### 1. **Axios** - Le navigateur automatique

```javascript
import axios from 'axios';

const response = await axios.get('https://www.honcon.de');
// response.data contient le HTML de la page
```

**RÃ´le :** TÃ©lÃ©charge le contenu HTML d'une page web, comme si vous ouvriez la page dans Chrome.

### 2. **Cheerio** - Le lecteur de HTML

```javascript
import * as cheerio from 'cheerio';

const $ = cheerio.load(response.data);
// $ est comme jQuery, permet de chercher dans le HTML
```

**RÃ´le :** Parse (analyse) le HTML et permet de chercher des Ã©lÃ©ments avec des sÃ©lecteurs CSS (comme `$('.event-card')`).

---

## ğŸ”„ Processus Ã©tape par Ã©tape

### Ã‰tape 1ï¸âƒ£ : TÃ©lÃ©charger la page web

```javascript
const response = await axios.get('https://www.honcon.de', {
  timeout: 10000,  // Attendre max 10 secondes
  headers: {
    // Se faire passer pour un vrai navigateur
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
  }
});
```

**RÃ©sultat :** `response.data` contient tout le HTML de la page

**Exemple de HTML reÃ§u :**
```html
<!DOCTYPE html>
<html>
  <body>
    <div class="event">
      <h2>HonCon 2025</h2>
      <p class="location">DÃ¼sseldorf, Germany</p>
      <p class="date">June 20-22, 2025</p>
      <a href="/tickets">Acheter</a>
    </div>
  </body>
</html>
```

---

### Ã‰tape 2ï¸âƒ£ : Parser le HTML avec Cheerio

```javascript
const $ = cheerio.load(response.data);
```

**RÃ´le :** Transforme le HTML en structure manipulable (DOM)

Maintenant on peut chercher des Ã©lÃ©ments comme avec jQuery :
- `$('.event')` â†’ tous les Ã©lÃ©ments avec la classe "event"
- `$('h2')` â†’ tous les titres h2
- `$('a').attr('href')` â†’ rÃ©cupÃ©rer l'attribut href d'un lien

---

### Ã‰tape 3ï¸âƒ£ : Chercher les conventions

```javascript
// Parcourir tous les Ã©lÃ©ments qui ont la classe "event"
$('.event').each((index, element) => {
  // Pour chaque Ã©lÃ©ment, extraire les infos
  const name = $(element).find('h2').text().trim();
  const location = $(element).find('.location').text().trim();
  const date = $(element).find('.date').text().trim();
  const url = $(element).find('a').attr('href');

  console.log(`TrouvÃ©: ${name} Ã  ${location}`);
});
```

**Analogie :** C'est comme utiliser Ctrl+F pour chercher "Supernatural" sur la page, puis noter toutes les informations autour.

---

### Ã‰tape 4ï¸âƒ£ : Filtrer et extraire les donnÃ©es

```javascript
$('.event').each((i, elem) => {
  const text = $(elem).text();  // Tout le texte de l'Ã©lÃ©ment

  // FILTRER : Ne garder que les conventions Supernatural
  if (text.toLowerCase().includes('supernatural')) {

    // EXTRAIRE les informations
    const name = $(elem).find('h2').text().trim();
    const location = extractLocation(text);  // Fonction helper
    const date = extractDate(text);          // Fonction helper
    const url = $(elem).find('a').attr('href');

    // CRÃ‰ER un objet convention
    conventions.push({
      id: generateId(name, date),
      name: name,
      location: location || 'Europe',
      date: date,
      url: url,
      source: 'HonCon',
      guests: []
    });
  }
});
```

---

### Ã‰tape 5ï¸âƒ£ : Extraire des infos spÃ©cifiques (dates, lieux)

Notre scraper utilise des **expressions rÃ©guliÃ¨res** (regex) pour trouver des patterns :

#### Extraction de dates

```javascript
function extractDate(text) {
  // Chercher diffÃ©rents formats de date
  const patterns = [
    // "15 June 2025" ou "June 15, 2025"
    /(\d{1,2}[\s-]+(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*[\s-]+\d{4})/i,

    // "15/06/2025" ou "15-06-2025"
    /(\d{1,2}[\/\-]\d{1,2}[\/\-]\d{4})/,

    // "2025-06-15" (format ISO)
    /(\d{4}[\s-]+\d{1,2}[\s-]+\d{1,2})/
  ];

  for (const pattern of patterns) {
    const match = text.match(pattern);
    if (match) {
      return match[1].trim();  // Retourne la date trouvÃ©e
    }
  }

  return null;  // Pas de date trouvÃ©e
}
```

**Exemple :**
- Texte : "La convention aura lieu le 15 June 2025 Ã  Paris"
- RÃ©sultat : "15 June 2025"

#### Extraction de lieux

```javascript
function extractLocation(text) {
  const locations = {
    'london': 'London, UK',
    'paris': 'Paris, France',
    'berlin': 'Berlin, Germany',
    // ... etc
  };

  const lowerText = text.toLowerCase();

  // Chercher si un nom de ville est mentionnÃ©
  for (const [key, value] of Object.entries(locations)) {
    if (lowerText.includes(key)) {
      return value;
    }
  }

  return null;
}
```

**Exemple :**
- Texte : "Convention at the London Hilton"
- RÃ©sultat : "London, UK"

---

### Ã‰tape 6ï¸âƒ£ : Sauvegarder en JSON

```javascript
async function saveResults() {
  const output = {
    lastUpdate: new Date().toISOString(),
    count: conventions.length,
    conventions: conventions
  };

  await fs.writeFile(
    'data/conventions.json',
    JSON.stringify(output, null, 2),
    'utf-8'
  );
}
```

CrÃ©e le fichier `data/conventions.json` :

```json
{
  "lastUpdate": "2025-12-07T16:00:00.000Z",
  "count": 3,
  "conventions": [
    {
      "id": "honcon-2025-germany",
      "name": "HonCon 2025",
      "location": "DÃ¼sseldorf, Germany",
      "date": "June 20-22, 2025",
      "url": "https://www.honcon.de",
      "source": "HonCon",
      "guests": ["Jensen Ackles"]
    }
  ]
}
```

---

## ğŸ¯ Exemple complet en action

Imaginons qu'on scrape cette page HTML :

```html
<html>
  <body>
    <div class="event">
      <h2>HonCon 2025 - Supernatural Convention</h2>
      <p>DÃ¼sseldorf, Germany</p>
      <p>June 20-22, 2025</p>
      <a href="/honcon-2025">Plus d'infos</a>
    </div>

    <div class="event">
      <h2>Comic Con Paris</h2>
      <p>Paris, France</p>
      <p>July 2025</p>
    </div>
  </body>
</html>
```

### Processus :

1. **TÃ©lÃ©chargement** : Axios rÃ©cupÃ¨re ce HTML
2. **Parsing** : Cheerio analyse le HTML
3. **Recherche** : `$('.event')` trouve les 2 divs
4. **Filtrage** :
   - 1er div contient "Supernatural" âœ… â†’ On garde
   - 2Ã¨me div ne contient pas "Supernatural" âŒ â†’ On ignore
5. **Extraction** :
   ```javascript
   name: "HonCon 2025 - Supernatural Convention"
   location: "DÃ¼sseldorf, Germany"  // extractLocation() trouve "dÃ¼sseldorf"
   date: "June 20-22, 2025"         // extractDate() trouve le pattern
   url: "https://www.honcon.de/honcon-2025"
   ```
6. **Sauvegarde** : Ã‰crit dans `data/conventions.json`

---

## ğŸ”„ Flux complet dans l'app

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. GitHub Actions (toutes les heures)     â”‚
â”‚     OU                                      â”‚
â”‚     npm run scrape (en local)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Scraper (scraper/scrape.js)            â”‚
â”‚     â€¢ Visite chaque site web               â”‚
â”‚     â€¢ TÃ©lÃ©charge le HTML                   â”‚
â”‚     â€¢ Parse avec Cheerio                   â”‚
â”‚     â€¢ Extrait les conventions              â”‚
â”‚     â€¢ Filtre "Supernatural" + "Europe"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. GÃ©nÃ¨re data/conventions.json           â”‚
â”‚     {                                       â”‚
â”‚       "count": 3,                           â”‚
â”‚       "conventions": [...]                  â”‚
â”‚     }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. GitHub Actions commit & push           â”‚
â”‚     (si changements dÃ©tectÃ©s)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. App Mobile (React Native)              â”‚
â”‚     â€¢ TÃ©lÃ©charge conventions.json          â”‚
â”‚     â€¢ Affiche les conventions              â”‚
â”‚     â€¢ Envoie notifications si nouvelles    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ Limitations et dÃ©fis

### 1. **Structure HTML changeante**

Les sites web changent rÃ©guliÃ¨rement leur code HTML.

**Avant :**
```html
<div class="event">
  <h2>HonCon 2025</h2>
</div>
```

**AprÃ¨s mise Ã  jour du site :**
```html
<article class="convention-card">
  <h3>HonCon 2025</h3>
</article>
```

Notre scraper ne trouve plus rien car il cherche `.event` et `h2` ! ğŸ’¥

**Solution :** Adapter les sÃ©lecteurs CSS rÃ©guliÃ¨rement.

### 2. **Protection anti-bot**

Certains sites dÃ©tectent et bloquent les scrapers :
- VÃ©rification du User-Agent
- CAPTCHA
- Rate limiting (limiter le nombre de requÃªtes)
- JavaScript obligatoire

**Solution :**
- Headers plus rÃ©alistes
- Puppeteer (vrai navigateur)
- Ou conventions manuelles

### 3. **Sites avec JavaScript**

Certains sites (comme Eventbrite) chargent les donnÃ©es avec JavaScript aprÃ¨s le chargement de la page.

**ProblÃ¨me :** Axios ne rÃ©cupÃ¨re que le HTML initial, pas ce qui est chargÃ© aprÃ¨s.

**Solution :** Utiliser Puppeteer qui simule un vrai navigateur.

---

## ğŸ’¡ Pourquoi les conventions manuelles ?

Pour contourner ces problÃ¨mes, on a ajoutÃ© `addManualConventions()` :

```javascript
function addManualConventions() {
  const manualConventions = [
    {
      id: 'honcon-2025-germany',
      name: 'HonCon 2025',
      location: 'DÃ¼sseldorf, Germany',
      date: 'June 20-22, 2025',
      url: 'https://www.honcon.de',
      source: 'Manual Entry',
      guests: ['Jensen Ackles', 'Jared Padalecki']
    }
  ];

  conventions.push(...manualConventions);
}
```

**Avantages :**
- âœ… Fiable Ã  100%
- âœ… Pas de problÃ¨me de scraping
- âœ… ContrÃ´le total sur les donnÃ©es
- âœ… Facile Ã  maintenir

**InconvÃ©nient :**
- âŒ NÃ©cessite mise Ã  jour manuelle

---

## ğŸ“ RÃ©sumÃ© simplifiÃ©

1. **Axios** tÃ©lÃ©charge le HTML d'un site (comme un navigateur)
2. **Cheerio** lit et analyse ce HTML (comme jQuery)
3. On **cherche** les Ã©lÃ©ments qui nous intÃ©ressent (`.event`, `h2`, etc.)
4. On **filtre** pour garder seulement Supernatural
5. On **extrait** les infos (nom, date, lieu, invitÃ©s)
6. On **sauvegarde** dans `conventions.json`
7. L'**app mobile** lit ce fichier et affiche les conventions

C'est comme si vous visitiez manuellement chaque site, mais en automatique et en quelques secondes ! ğŸš€

---

## ğŸ§ª Tester vous-mÃªme

```bash
# Lancer le scraper
npm run scrape

# Voir le rÃ©sultat
cat data/conventions.json
```

Vous verrez exactement ce processus en action dans les logs !

---

**Questions ?** Consultez `SCRAPING-GUIDE.md` pour aller plus loin ! ğŸ”¥
